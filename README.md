# map_reduce


MapReduce is a programming model used for processing large data sets with a distributed algorithm on a cluster. It simplifies the task of writing distributed programs by providing a clear structure for parallelizing computations.


The Map function takes an input pair and produces a set of intermediate key-value pairs.
The map function is applied in parallel to every item in the input dataset.
Example:
Input: (k1, v1)
Output: list((k2, v2))
Here, (k1, v1) is an input pair, and (k2, v2) is an intermediate key-value pair produced by the map function.

Reduce Function:
The Reduce function takes all the values associated with the same key and merges them together to form a potentially smaller set of values.
The reduce function is applied to the intermediate key-value pairs generated by the map function.
Example:
Input: (k2, list(v2))
Output: (k2, v3)
Here, (k2, list(v2)) is the input to the reduce function, where list(v2) is the list of all values associated with the key k2, and (k2, v3) is the output.


MapReduce Workflow:
The overall process can be broken down into several steps:

Splitting: The input data is split into chunks.

Mapping: The map function is applied to each chunk independently, producing intermediate key-value pairs.

Shuffling and Sorting: Intermediate key-value pairs are grouped by key (k2). This is often called the "shuffle and sort" phase.

Reducing: The reduce function is applied to each group of values that share the same key, producing the final output.

